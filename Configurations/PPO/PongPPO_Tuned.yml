env_id: PongNoFrameskip-v4
eval_frequency: 25000
experiment_name: PongPPO_Tuned
hyperparameters:
  batch_size: 128
  ent_coef: 0.0209
  gamma: 0.9805
  learning_rate: 0.000249
  n_steps: 384
  policy: CnnPolicy
  verbose: 1
model_architecture: PPO
n_envs: 4
n_stack: 4
steps_to_train: 10000000
